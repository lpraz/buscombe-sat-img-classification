{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part_4_Deliverable.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lejWSaXLbEQS",
        "colab_type": "text"
      },
      "source": [
        "# Setup\n",
        "Before running, make sure the following are uploaded to the root:\n",
        "* all_labels.json (Sentinel 2 labels)\n",
        "* nwpu_lakes_30samples.json\n",
        "* nwpu_lakes_20samplesA.json\n",
        "* nwpu_lakes_20samplesB.json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OY4FSdjTaGS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#colab = 0\n",
        "colab = 1\n",
        "\n",
        "if colab == 1:\n",
        "    %tensorflow_version 2.x\n",
        "    !pip install rasterio\n",
        "    #!pip install --default-timeout=1000 tensorflow-gpu==2.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpnHOKRKaWva",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVp6Bxr_aZWH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jThYQLf7bWQO",
        "colab_type": "text"
      },
      "source": [
        "# Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO0wV2OoeYoD",
        "colab_type": "text"
      },
      "source": [
        "## Download\n",
        "incl. Sentinel 2  images and masks, and NWPU images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52jWbhp_baI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    def get_confirm_token(response):\n",
        "        for key, value in response.cookies.items():\n",
        "            if key.startswith('download_warning'):\n",
        "                return value\n",
        "        \n",
        "        return None\n",
        "    \n",
        "    def save_response_content(response, destination):\n",
        "        CHUNK_SIZE = 32768\n",
        "\n",
        "        with open(destination, 'wb') as f:\n",
        "            for chunk in response.iter_content(CHUNK_SIZE):\n",
        "                if chunk: # Filter out keep-alive new chunks\n",
        "                    f.write(chunk)\n",
        "    \n",
        "    URL ='https://docs.google.com/uc?export=download'\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "    \n",
        "    save_response_content(response, destination)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GtoJkf-cR2c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "\n",
        "def unzip(f):\n",
        "    with zipfile.ZipFile(f, 'r') as zip_ref:\n",
        "        zip_ref.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRZT8P_QcdWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nwpu_imagery_id = '14kkcuU6wd9UMvjaDrg3PNI-e_voCi8HL'\n",
        "nwpu_imagery_zip = 'NWPU_imagery.zip'\n",
        "\n",
        "s2_imagery_id = '1iMfIjr_ul49Ghs2ewazjCt8HMPfhY47h'\n",
        "s2_imagery_zip = 's2cloudless_imagery.zip'\n",
        "\n",
        "s2_label_imagery_id = '1c7MpwKVejoUuW9F2UaF_vps8Vq2RZRfR'\n",
        "s2_label_imagery_zip = 's2cloudless_label_imagery.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0E0Y79sdJE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "download_file_from_google_drive(nwpu_imagery_id, nwpu_imagery_zip)\n",
        "download_file_from_google_drive(s2_imagery_id, s2_imagery_zip)\n",
        "download_file_from_google_drive(s2_label_imagery_id, s2_label_imagery_zip)\n",
        "\n",
        "unzip(nwpu_imagery_zip)\n",
        "unzip(s2_imagery_zip)\n",
        "unzip(s2_label_imagery_zip)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbSmIqxZiOWr",
        "colab_type": "text"
      },
      "source": [
        "## Clean up non-lake NWPU imagery"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lMSyGgviQke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, shutil\n",
        "\n",
        "try:\n",
        "    os.rename('images', 'nwpu_imagery')\n",
        "except:\n",
        "    pass\n",
        "\n",
        "subdirs = [x[0] for x in os.walk('nwpu_imagery')][1:]\n",
        "to_delete = [s for s in subdirs if 'lake' not in s]\n",
        "for k in to_delete:\n",
        "    shutil.rmtree(k, ignore_errors = True)\n",
        "os.rename('nwpu_imagery' + os.sep + 'lake', 'nwpu_imagery' + os.sep + 'data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e6TrQepERbo",
        "colab_type": "text"
      },
      "source": [
        "## Clean up .zips"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy7xt3H7ETo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.remove(nwpu_imagery_zip)\n",
        "os.remove(s2_imagery_zip)\n",
        "os.remove(s2_label_imagery_zip)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGPet6isej2-",
        "colab_type": "text"
      },
      "source": [
        "## Generate NWPU masks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEnCls6Hey9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "from PIL import Image, ImageDraw\n",
        "import numpy as np\n",
        "\n",
        "def write_mask(data, image_paths, images, i):\n",
        "    def get_data(data):\n",
        "        X = []\n",
        "        Y = []\n",
        "\n",
        "        for k in data['regions']:\n",
        "            X.append(data['regions'][k]['shape_attributes']['all_points_x'])\n",
        "            Y.append(data['regions'][k]['shape_attributes']['all_points_y'])\n",
        "        \n",
        "        return Y, X # Image coords flipped relative to JSON coords\n",
        "    \n",
        "    X, Y = get_data(data[image_paths[i]])\n",
        "    nx, ny, nz = np.shape(images[i])\n",
        "    mask = np.zeros((ny, nx))\n",
        "\n",
        "    for x, y in zip(X, Y):\n",
        "        polygon = np.vstack((x, y)).reshape((-1,), order = 'F').tolist()\n",
        "\n",
        "        if nx > ny or ny > nx:\n",
        "            x, y = y, x\n",
        "            img = Image.new('L', (ny, nx), 0)\n",
        "        else:\n",
        "            img = Image.new('L', (nx, ny), 0)\n",
        "        \n",
        "        ImageDraw.Draw(img).polygon(polygon, outline = 1, fill = 1)\n",
        "\n",
        "        m = np.flipud(np.rot90(np.array(img)))\n",
        "        try:\n",
        "            mask = mask + m\n",
        "        except:\n",
        "            mask = mask + m.T\n",
        "\n",
        "    matplotlib.image.imsave('nwpu_label_imagery' + os.sep + 'data' + os.sep + image_paths[i] + '_mask.jpg', mask.astype('uint8'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzGcYLg8ip7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.mkdir('nwpu_label_imagery')\n",
        "os.mkdir('nwpu_label_imagery' + os.sep + 'data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s13gSE7VivjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "data = []\n",
        "json_file = 'nwpu_lakes_30samples.json'\n",
        "data.append(json.load(open(json_file)))\n",
        "json_file = 'nwpu_lakes_20samplesA.json'\n",
        "data.append(json.load(open(json_file)))\n",
        "json_file = 'nwpu_lakes_20samplesB.json'\n",
        "data.append(json.load(open(json_file)))\n",
        "\n",
        "data_merged = {}\n",
        "for d in data:\n",
        "    data_merged.update(d)\n",
        "\n",
        "nwpu_image_paths = sorted(data_merged.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL7nmSeFhKLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nwpu_dir_path = 'nwpu_imagery' + os.sep + 'data'\n",
        "nwpu_all_image_paths = [f for f in os.listdir(nwpu_dir_path) if os.path.isfile(os.path.join(nwpu_dir_path, f))]\n",
        "\n",
        "for path in nwpu_all_image_paths:\n",
        "    if path not in nwpu_image_paths:\n",
        "        os.remove(os.path.join(nwpu_dir_path, path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Bx3htYtjY9o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import rasterio\n",
        "\n",
        "nwpu_images = []\n",
        "for path in nwpu_image_paths:\n",
        "    with rasterio.open('nwpu_imagery' + os.sep + 'data' + os.sep + path) as dataset:\n",
        "        nwpu_images.append(dataset.read().T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4K3526kjuH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(nwpu_image_paths)):\n",
        "    write_mask(data_merged, nwpu_image_paths, nwpu_images, i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAaYJK7wrGMq",
        "colab_type": "text"
      },
      "source": [
        "## Image batch generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Wht-KplrIGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image_batch_generator(img_dir, mask_dir, files, batch_size = 32, sz = (512, 512)):\n",
        "    while True: # loop infinitely, as long as called by training function\n",
        "        batch = np.random.choice(files, size = batch_size)\n",
        "\n",
        "        batch_x = []\n",
        "        batch_y = []\n",
        "\n",
        "        for f in batch:\n",
        "            raw_path = f'{img_dir}/data/{f}'\n",
        "            raw = Image.open(raw_path)\n",
        "            raw = raw.resize(sz)\n",
        "            raw = np.array(raw)\n",
        "\n",
        "            # Make RGB from...\n",
        "            if len(raw.shape) == 2: # grayscale\n",
        "                raw = np.stack((raw,) * 3, axis = -1)\n",
        "            else: # RGBA\n",
        "                raw = raw[:, :, 0:3]\n",
        "            \n",
        "            # Crop image square\n",
        "            nx, ny, nz = np.shape(raw)\n",
        "            n = np.minimum(nx, ny)\n",
        "            raw = raw[:n, :n, :]\n",
        "\n",
        "            batch_x.append(raw)\n",
        "\n",
        "            # Get masks\n",
        "            mask_path = f'{mask_dir}/data/{f}_mask.jpg'\n",
        "            mask = Image.open(mask_path)\n",
        "            mask = np.max(np.array(mask.resize(sz)), axis = 2) # Flatten to 2D\n",
        "            mask = (mask > 100).astype('int') # Water pixels > 100 in mask\n",
        "\n",
        "            mask = mask[:n, :n]\n",
        "\n",
        "            batch_y.append(mask)\n",
        "        \n",
        "        # Preprocess batch\n",
        "        batch_x = np.array(batch_x) / 255 # Normalize to [0, 1]\n",
        "        batch_y = np.array(batch_y)\n",
        "        batch_y = np.expand_dims(batch_y, 3) # Add singleton dimension\n",
        "\n",
        "        yield (batch_x, batch_y) # Yield images and masks together"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvs0VkFJkhaL",
        "colab_type": "text"
      },
      "source": [
        "## Augmentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOYNgHsgvOAw",
        "colab_type": "text"
      },
      "source": [
        "### Make generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi-Hiaubkn97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 111\n",
        "batch_size = 1\n",
        "\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    featurewise_center = False,\n",
        "    featurewise_std_normalization = False,\n",
        "    shear_range = 0,\n",
        "    zoom_range = 0.2,\n",
        "    rotation_range = 45,\n",
        "    horizontal_flip = True)\n",
        "\n",
        "s2_image_generator = datagen.flow_from_directory(\n",
        "    's2cloudless_imagery',\n",
        "    target_size = (512, 512),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = None,\n",
        "    seed = SEED,\n",
        "    shuffle = False)\n",
        "\n",
        "s2_mask_generator = datagen.flow_from_directory(\n",
        "    's2cloudless_label_imagery',\n",
        "    target_size = (512, 512),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = None,\n",
        "    seed = SEED,\n",
        "    shuffle = False)\n",
        "\n",
        "nwpu_image_generator = datagen.flow_from_directory(\n",
        "    'nwpu_imagery',\n",
        "    target_size = (512, 512),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = None,\n",
        "    seed = SEED,\n",
        "    shuffle = False)\n",
        "\n",
        "nwpu_mask_generator = datagen.flow_from_directory(\n",
        "    'nwpu_label_imagery',\n",
        "    target_size = (512, 512),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = None,\n",
        "    seed = SEED,\n",
        "    shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14WKQCg3jWCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u8jcVDTvPYJ",
        "colab_type": "text"
      },
      "source": [
        "### Generate, save augmented images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9go9KXpIB-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_augmented_images(n_aug_files, generator, image_dir, label_dir):\n",
        "    for counter in range(n_aug_files):\n",
        "        x, y = next(generator)\n",
        "        matplotlib.image.imsave(image_dir + os.sep + 'data' + os.sep + 'augimage' + str(counter) + '.jpg', np.squeeze(x[0]))\n",
        "        matplotlib.image.imsave(label_dir + os.sep + 'data' + os.sep + 'augimage' + str(counter) + '.jpg_mask.jpg', np.squeeze(y[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOzj9tQsIEZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s2_n_aug_files = 100\n",
        "s2_aug_generator = (tuple(np.array(pair, dtype = 'float64') / 255) for pair in zip(s2_image_generator, s2_mask_generator))\n",
        "make_augmented_images(s2_n_aug_files, s2_aug_generator, 's2cloudless_imagery', 's2cloudless_label_imagery')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gtfBCLXwPzt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nwpu_n_aug_files = 140\n",
        "nwpu_aug_generator = (tuple(np.array(pair, dtype = 'float64') / 255) for pair in zip(nwpu_image_generator, nwpu_mask_generator))\n",
        "make_augmented_images(nwpu_n_aug_files, nwpu_aug_generator, 'nwpu_imagery', 'nwpu_label_imagery')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXeVINMDx5Jy",
        "colab_type": "text"
      },
      "source": [
        "## Make datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MW0lHTZgx9mg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from random import shuffle\n",
        "\n",
        "prop_train = 0.6\n",
        "\n",
        "s2_batch_size = 16\n",
        "nwpu_batch_size = 16\n",
        "\n",
        "s2_image_paths = os.listdir('s2cloudless_imagery/data')\n",
        "nwpu_image_paths = os.listdir('nwpu_imagery/data')\n",
        "\n",
        "shuffle(s2_image_paths)\n",
        "shuffle(nwpu_image_paths)\n",
        "\n",
        "s2_split = int(prop_train * len(s2_image_paths))\n",
        "nwpu_split = int(prop_train * len(nwpu_image_paths))\n",
        "\n",
        "s2_train_image_paths = s2_image_paths[0:s2_split]\n",
        "s2_test_image_paths = s2_image_paths[s2_split:]\n",
        "nwpu_train_image_paths = nwpu_image_paths[0:nwpu_split]\n",
        "nwpu_test_image_paths = nwpu_image_paths[nwpu_split:]\n",
        "\n",
        "s2_train_generator = image_batch_generator('s2cloudless_imagery', 's2cloudless_label_imagery', s2_train_image_paths, batch_size = batch_size)\n",
        "s2_test_generator = image_batch_generator('s2cloudless_imagery', 's2cloudless_label_imagery', s2_test_image_paths, batch_size = batch_size)\n",
        "nwpu_train_generator = image_batch_generator('nwpu_imagery', 'nwpu_label_imagery', nwpu_train_image_paths, batch_size = batch_size)\n",
        "nwpu_test_generator = image_batch_generator('nwpu_imagery', 'nwpu_label_imagery', nwpu_test_image_paths, batch_size = batch_size)\n",
        "\n",
        "s2_train_steps = len(s2_train_image_paths) // batch_size\n",
        "s2_test_steps = len(s2_test_image_paths) // batch_size\n",
        "nwpu_train_steps = len(nwpu_train_image_paths) // batch_size\n",
        "nwpu_test_steps = len(nwpu_test_image_paths) // batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN7GEktlmLrU",
        "colab_type": "text"
      },
      "source": [
        "# U-Net Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdbGKPPjmM3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mean_iou(y_true, y_pred):\n",
        "    yt0 = y_true[:, :, :, 0]\n",
        "    yp0 = tf.keras.backend.cast(y_pred[:, :, :, 0] > 0.5, 'float32')\n",
        "    inter = tf.math.count_nonzero(tf.logical_and(tf.equal(yt0, 1), tf.equal(yp0, 1)))\n",
        "    union = tf.math.count_nonzero(tf.add(yt0, yp0))\n",
        "    iou = tf.where(tf.equal(union, 0), 1., tf.cast(inter / union, 'float32'))\n",
        "    return iou"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dceXzr_pMZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.layers import Concatenate, Conv2DTranspose\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def unet(sz = (512, 512, 3)):\n",
        "    inputs = Input(sz)\n",
        "    _ = inputs\n",
        "\n",
        "    # Downsampling\n",
        "    f = 8\n",
        "    layers = []\n",
        "\n",
        "    for i in range(6):\n",
        "        _ = Conv2D(f, 3, activation = 'relu', padding = 'same')(_)\n",
        "        _ = Conv2D(f, 3, activation = 'relu', padding = 'same')(_)\n",
        "        layers.append(_)\n",
        "        _ = MaxPooling2D()(_)\n",
        "        f = f * 2\n",
        "    \n",
        "    # Bottleneck\n",
        "    ff2 = 64\n",
        "\n",
        "    j = len(layers) - 1\n",
        "    _ = Conv2D(f, 3, activation = 'relu', padding = 'same')(_)\n",
        "    _ = Conv2D(f, 3, activation = 'relu', padding = 'same')(_)\n",
        "    _ = Conv2DTranspose(ff2, 2, strides = (2, 2), padding = 'same')(_)\n",
        "    _ = Concatenate(axis = 3)([_, layers[j]])\n",
        "    j = j - 1\n",
        "\n",
        "    # Upsampling\n",
        "    for i in range(5):\n",
        "        ff2 = ff2 // 2\n",
        "        f = f // 2\n",
        "        _ = Conv2D(f, 3, activation = 'relu', padding = 'same')(_)\n",
        "        _ = Conv2D(f, 3, activation = 'relu', padding = 'same')(_)\n",
        "        _ = Conv2DTranspose(ff2, 2, strides = (2, 2), padding = 'same')(_)\n",
        "        _ = Concatenate(axis = 3)([_, layers[j]])\n",
        "        j = j - 1\n",
        "\n",
        "    # Classification\n",
        "    _ = Conv2D(f, 3, activation = 'relu', padding = 'same')(_)\n",
        "    _ = Conv2D(f, 3, activation = 'relu', padding = 'same')(_)\n",
        "    outputs = Conv2D(1, 1, activation = 'sigmoid')(_)\n",
        "\n",
        "    # Model creation\n",
        "    model = Model(inputs = [inputs], outputs = [outputs])\n",
        "    model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = [mean_iou])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tO3jysWevtt7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s2_model = unet()\n",
        "nwpu_model = unet()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8wSk6O9QfJ_",
        "colab_type": "text"
      },
      "source": [
        "## Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfMKyiKQQjMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PlotLearning(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.i = 0\n",
        "        self.x = []\n",
        "        self.losses = []\n",
        "        self.val_losses = []\n",
        "        self.acc = []\n",
        "        self.val_acc = []\n",
        "        #self.fig = plt.figure()\n",
        "        self.logs = []\n",
        "    \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.logs.append(logs)\n",
        "        self.x.append(self.i)\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.val_losses.append(logs.get('val_loss'))\n",
        "        self.acc.append(logs.get('mean_iou'))\n",
        "        self.val_acc.append(logs.get('val_mean_iou'))\n",
        "        self.i += 1\n",
        "        print('i=',self.i,'loss=',logs.get('loss'),'val_loss=',logs.get('val_loss'),'mean_iou=',logs.get('mean_iou'),'val_mean_iou=',logs.get('val_mean_iou'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ06c7K9Q2js",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "\n",
        "class GarbageCollect(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs = {}):\n",
        "        pass\n",
        "    \n",
        "    def on_epoch_end(self, epoch, logs = {}):\n",
        "        gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pr0sO9KSQZaI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_callbacks():\n",
        "    checkpointer = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath = 'unet.h5',\n",
        "        verbose = 0,\n",
        "        save_best_only = True,\n",
        "        save_weights_only = True)\n",
        "    callbacks = [checkpointer, PlotLearning(), GarbageCollect()]\n",
        "    return callbacks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrtxxXmrq_BK",
        "colab_type": "text"
      },
      "source": [
        "# Train/Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW8i2ujjgDda",
        "colab_type": "text"
      },
      "source": [
        "## Train/test on own datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OUzPZ5u0FVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Disabling multiprocessing, using 1-sized queue to avoid ballooning RAM usage\n",
        "\n",
        "s2_history = s2_model.fit(\n",
        "    x = s2_train_generator,\n",
        "    epochs = 200,\n",
        "    steps_per_epoch = s2_train_steps,\n",
        "    validation_data = s2_test_generator,\n",
        "    validation_steps = s2_test_steps,\n",
        "    callbacks = build_callbacks(),\n",
        "    verbose = 1,\n",
        "    use_multiprocessing = False,\n",
        "    max_queue_size = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cuwWJ-jdyEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nwpu_history = nwpu_model.fit(\n",
        "    x = nwpu_train_generator,\n",
        "    epochs = 200,\n",
        "    steps_per_epoch = nwpu_train_steps,\n",
        "    validation_data = nwpu_test_generator,\n",
        "    validation_steps = nwpu_test_steps,\n",
        "    callbacks = build_callbacks(),\n",
        "    verbose = 1,\n",
        "    use_multiprocessing = False,\n",
        "    max_queue_size = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J53TrHSNgE-c",
        "colab_type": "text"
      },
      "source": [
        "## Test on other datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xq5dYwC0duOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s2_cross_eval = s2_model.evaluate(\n",
        "    x = nwpu_train_generator,\n",
        "    verbose = 1,\n",
        "    steps = nwpu_test_steps,\n",
        "    callbacks = build_callbacks(),\n",
        "    use_multiprocessing = False,\n",
        "    max_queue_size = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGw5a-kud0C6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nwpu_cross_eval = nwpu_model.evaluate(\n",
        "    x = s2_train_generator,\n",
        "    verbose = 1,\n",
        "    steps = s2_test_steps,\n",
        "    callbacks = build_callbacks(),\n",
        "    use_multiprocessing = False,\n",
        "    max_queue_size = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SXym6drq_8E",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate on own datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxp4bCM3aTXm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(s2_history.history.keys())\n",
        "print(nwpu_history.history.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CnkinqvahX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_history(s2_history, nwpu_history):\n",
        "    plt.figure(figsize = (10, 10))\n",
        "\n",
        "    plt.subplot(121)\n",
        "    plt.plot(s2_history.history['mean_iou'], 'k', lw = 1) # Training IoU curve\n",
        "    plt.plot(s2_history.history['val_mean_iou'], 'r', lw = 1) # Test IoU curve\n",
        "    plt.ylim(0, 1) # Y axis limits\n",
        "    plt.title('S2 model IoU')\n",
        "    plt.ylabel('IoU')\n",
        "    plt.xlabel('Epoch number')\n",
        "    plt.legend(['train', 'test'], loc = 'upper left')\n",
        "\n",
        "    plt.subplot(122)\n",
        "    plt.plot(nwpu_history.history['mean_iou'], 'k', lw = 1)\n",
        "    plt.plot(nwpu_history.history['val_mean_iou'], 'r', lw = 1)\n",
        "    plt.ylim(0, 1)\n",
        "    plt.title('NWPU model IoU')\n",
        "    plt.ylabel('IoU')\n",
        "    plt.xlabel('Epoch number')\n",
        "    plt.legend(['train', 'test'], loc = 'upper left')\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wH5G9LPigS8i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_history(s2_history, nwpu_history)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}