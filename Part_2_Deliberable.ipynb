{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = '14kkcuU6wd9UMvjaDrg3PNI-e_voCi8HL'\n",
    "nwpu_images_path = 'NWPU_images.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download NWPU-RESISC45 satellite imagery (Google Drive)\n",
    "Warning: will download 405MB. Will only use images of lakes, and then only those that already have labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# From Part_1_GettingStarted.ipynb\n",
    "# Which is in turn from https://stackoverflow.com/questions/38511444/python-download-files-from-google-drive-using-url\n",
    "def get_file(id, destination):\n",
    "    def get_confirm_token(response):\n",
    "        for key, value in response.cookies.items():\n",
    "            if key.startswith('download_warning'):\n",
    "                return value\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def save_response_content(response, destination):\n",
    "        CHUNK_SIZE = 32768\n",
    "        \n",
    "        with open(destination, 'wb') as f:\n",
    "            for chunk in response.iter_content(CHUNK_SIZE):\n",
    "                if chunk: # Filter out keep-alive new chunks\n",
    "                    f.write(chunk)\n",
    "    \n",
    "    URL = 'https://docs.google.com/uc?export=download'\n",
    "    \n",
    "    session = requests.Session()\n",
    "    \n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "    \n",
    "    if token:\n",
    "        params = { 'id' : id, 'confirm' : token }\n",
    "        response = session.get(URL, params = params, stream = True)\n",
    "    \n",
    "    save_response_content(response, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "def unzip(path):\n",
    "    with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "        zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_file(file_id, nwpu_images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unzip(nwpu_images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "\n",
    "# Rename folder for clarity\n",
    "try:\n",
    "    os.rename('images', 'nwpu_images')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Remove everything that isn't a picture of a lake\n",
    "non_lake_subdirs = [s for s in [x[0] for x in os.walk('nwpu_images')][1:] if 'lake' not in s]\n",
    "for subdir in non_lake_subdirs:\n",
    "    shutil.rmtree(subdir, ignore_errors=True)\n",
    "\n",
    "# Rename lake subdir to 'data'\n",
    "os.rename('nwpu_images' + os.sep + 'lake', 'nwpu_images' + os.sep + 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create labels\n",
    "This is a manual process, and must be done through [makesense.io](https://makesense.io). We'll use labels that were already created/in the repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename, segment into folders (training_images, validation_images, test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def move_images_from_polys(polys, folder_name):\n",
    "    for filename in polys:\n",
    "        shutil.move(\n",
    "            'nwpu_images' + os.sep + 'data' + os.sep + filename,\n",
    "            'nwpu_images' + os.sep + 'data' + os.sep + folder_name + os.sep + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_polys = json.load(open('nwpu_labels' + os.sep + 'nwpu_lakes_30samples.json'))\n",
    "validation_polys = json.load(open('nwpu_labels' + os.sep + 'nwpu_lakes_20samplesA.json'))\n",
    "test_polys = json.load(open('nwpu_labels' + os.sep + 'nwpu_lakes_20samplesB.json'))\n",
    "\n",
    "try:\n",
    "    os.mkdir('nwpu_images' + os.sep + 'data' + os.sep + 'training')\n",
    "    os.mkdir('nwpu_images' + os.sep + 'data' + os.sep + 'validation')\n",
    "    os.mkdir('nwpu_images' + os.sep + 'data' + os.sep + 'test')\n",
    "\n",
    "    move_images_from_polys(training_polys, 'training')\n",
    "    move_images_from_polys(validation_polys, 'validation')\n",
    "    move_images_from_polys(test_polys, 'test')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir('nwpu_images' + os.sep + 'data'):\n",
    "    if (filename.endswith('.jpg')):\n",
    "        os.remove('nwpu_images' + os.sep + 'data' + os.sep + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make mask images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(poly):\n",
    "    X = []; Y = []\n",
    "    for k in poly['regions']: # For each polygon...\n",
    "        X.append(poly['regions'][k]['shape_attributes']['all_points_x'])\n",
    "        Y.append(poly['regions'][k]['shape_attributes']['all_points_y'])\n",
    "    return Y, X # JSON coordinates are flipped relative to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import matplotlib\n",
    "import matplotlib.image\n",
    "import numpy as np\n",
    "\n",
    "def write_mask(image_name, poly, image, folder_name):\n",
    "    X, Y = get_data(poly)\n",
    "    \n",
    "    # Get image dimensions\n",
    "    nx, ny, nz = np.shape(image)\n",
    "    mask = np.zeros((ny, nx))\n",
    "    \n",
    "    for x, y in zip(X, Y):\n",
    "        # Interweave xs and ys\n",
    "        polygon = np.vstack((x, y)).reshape((-1,), order='F').tolist()\n",
    "        \n",
    "        # Create mask image based on polygon\n",
    "        if nx != ny:\n",
    "            x, y = y, x\n",
    "            img = Image.new('L', (ny, nx), 0)\n",
    "        else:\n",
    "            img = Image.new('L', (nx, ny), 0)\n",
    "        \n",
    "        ImageDraw.Draw(img).polygon(polygon, outline=1, fill=1)\n",
    "        \n",
    "        # Turn into numpy array\n",
    "        m = np.flipud(np.rot90(np.array(img)))\n",
    "        try:\n",
    "            mask = mask + m\n",
    "        except:\n",
    "            mask = mask + m.T\n",
    "    \n",
    "    matplotlib.image.imsave(\n",
    "        'nwpu_label_imagery' + os.sep + 'data' + os.sep + folder_name + os.sep + image_name + '_mask.jpg',\n",
    "        mask.astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_masks(polys, images, folder_name):\n",
    "    for image_name in polys:\n",
    "        write_mask(image_name, polys[image_name], images[image_name], folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "\n",
    "def get_images(image_names, folder_name):\n",
    "    images = {}\n",
    "    for image_name in image_names:\n",
    "        with rasterio.open('nwpu_images' + os.sep + 'data' + os.sep + folder_name + os.sep + image_name) as dataset:\n",
    "            images[image_name] = dataset.read().T\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('nwpu_label_imagery')\n",
    "    os.mkdir('nwpu_label_imagery' + os.sep + 'data')\n",
    "    os.mkdir('nwpu_label_imagery' + os.sep + 'data' + os.sep + 'training')\n",
    "    os.mkdir('nwpu_label_imagery' + os.sep + 'data' + os.sep + 'validation')\n",
    "    os.mkdir('nwpu_label_imagery' + os.sep + 'data' + os.sep + 'test')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "training_images = get_images(training_polys, 'training')\n",
    "validation_images = get_images(validation_polys, 'validation')\n",
    "test_images = get_images(test_polys, 'test')\n",
    "\n",
    "write_masks(training_polys, training_images, 'training')\n",
    "write_masks(validation_polys, validation_images, 'validation')\n",
    "write_masks(test_polys, test_images, 'test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
