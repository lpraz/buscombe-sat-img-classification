{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part_3_Deliverable.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qZ4p_lp8dvd",
        "colab_type": "text"
      },
      "source": [
        "#### Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5BMhbJQ8Lvd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9f662a7c-c106-4054-c1e4-23bce8c75eeb"
      },
      "source": [
        "!pip install --default-timeout=1000 tensorflow-gpu==2.0\n",
        "!pip install rasterio\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# GPU OK?\n",
        "tf.test.is_gpu_available()\n",
        "\n",
        "colab = 'google.colab' in str(get_ipython())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/44/47f0722aea081697143fbcf5d2aa60d1aee4aaacb5869aee2b568974777b/tensorflow_gpu-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (380.8MB)\n",
            "\u001b[K     |████████████████████████████████| 380.8MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (1.18.5)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (3.12.4)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 48.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (0.35.1)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 45.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (3.3.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (1.1.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (1.31.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (1.15.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0) (49.6.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (1.17.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0) (2.10.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (4.6)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (1.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=92fae6ef065b778bdca4f598953a96725a9f0ae2e13efd0029911270230c4244\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorboard<3,>=2.3.0, but you'll have tensorboard 2.0.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorflow-estimator<2.4.0,>=2.3.0, but you'll have tensorflow-estimator 2.0.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, keras-applications, gast, tensorflow-gpu\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-2.0.2 tensorflow-estimator-2.0.1 tensorflow-gpu-2.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXXXa7vexS8y",
        "colab_type": "text"
      },
      "source": [
        "#### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RPeymBWxURg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 8 # Number of images to pass to each model training epoch\n",
        "prop_train = 0.5 # Proportion of all images to use for training\n",
        "num_epochs = 100\n",
        "img_size = 124"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gqjx169epWSM",
        "colab_type": "text"
      },
      "source": [
        "### Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTUZcTuDsi0g",
        "colab_type": "text"
      },
      "source": [
        "#### Download imagery"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slwiF3obqdXZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = 'https://docs.google.com/us?export=download'\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id'  id}, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : 'token' }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "  \n",
        "    save_response_content(response, destination)\n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return true\n",
        "  \n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, 'wb') as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yk3IOFtZrjVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unzip(f):\n",
        "    with zipfile.ZipFile(f, 'r') as zip_ref:\n",
        "        zip_ref.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaoNuB6zrMYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download imagery\n",
        "download_file_from_google_drive(\n",
        "    '1iMfIjr_ul49Ghs2ewazjCt8HMPfhY47h',\n",
        "    's2cloudless_imagery.zip')\n",
        "unzip('s2cloudless_imagery.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhgkuPowrRWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download label images (masks)\n",
        "download_file_from_google_drive(\n",
        "    '1c7MpwKVejoUuW9F2UaF_vps8Vq2RZRfR',\n",
        "    's2cloudless_label_imagery.zip')\n",
        "unzip('s2cloudless_label_imagery.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5e5jmFK3MSz",
        "colab_type": "text"
      },
      "source": [
        "#### Crop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EuRUgXj3NiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import rasterio, json, os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "data = json.load(open('all_labels.json'))\n",
        "images = sorted(data.keys())\n",
        "\n",
        "all_images = []\n",
        "N = [] # List of min dimensions, will be used for cropping\n",
        "\n",
        "for image in images:\n",
        "    with rasterio.open('s2cloudless_imagery' + os.sep + 'data' + os.sep + image) as dataset:\n",
        "        tmp = np.squeeze(np.array(dataset.read().T)) # Read data, transpose\n",
        "        nx, ny, _ = np.shape(tmp) # Get dimensions\n",
        "        n = np.minimum(nx, ny) # Minimum dimension\n",
        "        all_images.append(tmp)\n",
        "        N.append(n)\n",
        "\n",
        "n = np.min(N) # Find smallest dimension, period\n",
        "all_images = [1[:n, n:] for l in all_images] # Crop all images to that dimension\n",
        "all_images = np.array(all_images) # Convert list to a numpy array\n",
        "\n",
        "# Resize each image, keep only the first/red band\n",
        "all_images2 = np.zeros((40, img_size, img_size))\n",
        "counter = 0\n",
        "for k in all_images:\n",
        "    all_images2[counter, :, :] = np.squeeze(tf.image.resize(k, (img_size, img_size), method='nearest'))[:, :, 0]\n",
        "    counter += 1\n",
        "\n",
        "del all_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTDYfvpE5Ttd",
        "colab_type": "text"
      },
      "source": [
        "#### Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWqQTzCe5U2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = all_images2[:30, :, :]\n",
        "x_test = all_images2[:30, :, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lH0Q9a4sscB",
        "colab_type": "text"
      },
      "source": [
        "#### Dataset generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq-ml02tsvia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def image_batch_generator(files, batch_size = 32, sz = (512, 512)):\n",
        "    while True: # loop as many times as the training function calls it\n",
        "        # Extract a random subset of files of length batch_size\n",
        "        batch = np.random.choice(files, size=batch_size)\n",
        "\n",
        "        batch_in = []\n",
        "        batch_out = []\n",
        "\n",
        "        # Cycle through each image in the batch\n",
        "        for f in batch:\n",
        "        # Preprocess raw images\n",
        "            rawfile = f's2cloudless_imagery/data/{f}'\n",
        "            raw = Image.open(rawfile)\n",
        "            raw = raw.resize(sz)\n",
        "            raw = np.array(raw)\n",
        "\n",
        "            # Check the number of channels (some may be RGBA, some may be grayscale)\n",
        "            if len(raw.shape) == 2:\n",
        "                raw = np.stack((raw,) * 3, axis = -1)\n",
        "            else:\n",
        "                raw = raw[:, :, 0:3]\n",
        "            \n",
        "            # Crop the image square based on min(height, width)\n",
        "            nx, ny, nz = np.shape(raw)\n",
        "            n = np.minimum(nx, ny)\n",
        "            raw = raw[:n, :n, :]\n",
        "\n",
        "            batch_x.append(raw)\n",
        "\n",
        "            # Get masks\n",
        "            maskfile = rawfile.replace('s2cloudless_imagery', 's2cloudless_label_imagery') + '_masks.jpg'\n",
        "            mask = Image.open(maskfile)\n",
        "            mask = np.max(np.array(mask.resize(sz)), axis = 2) # Flatten 3D mask to 2D\n",
        "            mask = (mask > 100).astype('int') # Water pixels are always > 100\n",
        "        \n",
        "        # Preprocess batch\n",
        "        batch_x = np.array(batch_x) / 255 # Normalize to [0, 1]\n",
        "        batch_y = np.array(batch_y)\n",
        "        batch_y = np.expand_dims(batch_y, 3) # Add singleton dimension\n",
        "\n",
        "        yield (batch_x, batch_y) # Yield images and labels together"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQKsihBBw4rT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "split = int(prop_train * len(images))\n",
        "train_files = image_files[:split]\n",
        "test_files = image_files[split:]\n",
        "\n",
        "train_generator = image_batch_generator(train_files, batch_size = batch_size)\n",
        "test_generator = image_batch_generator(test_files, batch_size = batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrYvp2CFyRJp",
        "colab_type": "text"
      },
      "source": [
        "#### Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0o_39QKzJg9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_gen_args = dict(\n",
        "    featurewise_center = True,\n",
        "    featurewise_std_normalization = True,\n",
        "    rotation_range = 90,\n",
        "    width_shift_range = 0.1,\n",
        "    height_shift_range = 0.1,\n",
        "    zoom_range = 0.2)\n",
        "image_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**data_gen_args)\n",
        "mask_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**data_gen_args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg7XOek3jCdP",
        "colab_type": "text"
      },
      "source": [
        "### IoU (Intersection over Union/Jaccard metric)\n",
        "Numerator: number of pixels common to the true and predicted masks.\n",
        "Denominator: total number of pixels across both masks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWNOOucJhGc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# IoU = y_true `isct` y_pred / y_true `union` y_pred\n",
        "# Numerator\n",
        "def mean_iou(true, pred): \n",
        "  t0 = true[:,:,:,0] # Use the 3D image, not the 4D tensor\n",
        "  # Binarize (either 0 or 1, land or lake) and convert to float\n",
        "  p0 = tf.keras.backend.cast(pred[:, :, :, 0] > 0.5, 'float32')\n",
        "  # Get the intersection (numerator in IoU)\n",
        "  isct = tf.math.count_nonzero(tf.logical_and(tf.equal(t0, 1), tf.equal(p0, 1)))\n",
        "  # Get the union (denominator in IoU)\n",
        "  union = tf.math.count_nonzero(tf.add(t0, p0))\n",
        "  # Compute IoU as the ratio unless the denominator is zero\n",
        "  iou = tf.where(tf.equal(union, 0), 1., tf.cast(inter / union, 'float32'))\n",
        "  return iou"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7dr1pVRo1Gi",
        "colab_type": "text"
      },
      "source": [
        "### U-Net details"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKsOUArgjS4n",
        "colab_type": "text"
      },
      "source": [
        "#### Encoder\n",
        "Our U-Net starts with a 512x512x3 (in RGB) image. We downsample this to 8x8x256 progressively using six banks of convolutional filters. Each filter is double the size of the previous filter, and therefore downsamples the image to half its previous size while features are extracted using max pooling.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdC0pDtvshIO",
        "colab_type": "text"
      },
      "source": [
        "#### Bottleneck\n",
        "A very low-dimensional feature representation of a high-dimensional input. The goal is to only capture the essential information of our problem domain from a large image. Our 8x8x256 tensor now becomes a 16x16x320 'bottleneck' with much less parameters than the original input (>780k vs. <82k)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qkcR-lDkR5G",
        "colab_type": "text"
      },
      "source": [
        "#### Decoder\n",
        "In the opposite direction, we upsample our bottlenecked 16x16x320 image from the encoding step, again progressively with six banks of convolutional filters. Each filter is half the size of the previous filter, and therefore upsamples the image to double its previous size while features are extracted through transposed convolutions and concatenation.\n",
        "\n",
        "A transposed convolution layer convolves a dilated version of the input tensor in order to upscale the output. It does this by interleaving zeroed rows and columns between each pair of adjacent rows and columns in the input tensor. The dilation rate is the stride length (in this case, 2x2)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4cmiQ_KlG6c",
        "colab_type": "text"
      },
      "source": [
        "We end with a classification layer using a convolution layer that maps the output of the previous layers to a single 2D output with values ranging from 0 to 1 based on a sigmoid activation function (which is ideal for binary classification)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DnsVQm6o7Zr",
        "colab_type": "text"
      },
      "source": [
        "Construct the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toIdUub5o-Cv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Concatenate, Conv2D, Conv2DTranspose, Input, MaxPooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def make_model():\n",
        "  inputs = Input((512, 512, 3))\n",
        "  _tensor = inputs\n",
        "\n",
        "  # ~Downsample~\n",
        "\n",
        "  # Start with an 8-pixel kernel for the convolutional filter.\n",
        "  # We double this at each encode step, then halve at each decode step\n",
        "  f = 8 \n",
        "  layers = []\n",
        "\n",
        "  # 6 iterations of downsampling, each reusing _tensor\n",
        "  # For each...\n",
        "  #   Pass through 2 convolutional blocks, append to the 'layers' output list\n",
        "  #   Then apply max pooling, and double the filter size for the next iteration\n",
        "  for i in range(0, 6):\n",
        "    _tensor = Conv2D(f, 3, activation = 'relu', padding = 'same') (_tensor)\n",
        "    _tensor = Conv2D(f, 3, activation = 'relu', padding = 'same') (_tensor)\n",
        "    layers.append(_tensor)\n",
        "    _tensor = MaxPooling2D() (_tensor)\n",
        "    f = f * 2\n",
        "  \n",
        "  # ~Bottleneck~\n",
        "\n",
        "  ff2 = 64\n",
        "  j = len(layers) - 1\n",
        "\n",
        "  _tensor = Conv2D(f, 3, activation = 'relu', padding = 'same') (_tensor)\n",
        "  _tensor = Conv2D(f, 3, activation = 'relu', padding = 'same') (_tensor)\n",
        "  _tensor = Conv2DTranspose(ff2, 2, strides = (2, 2), padding = 'same') (_tensor)\n",
        "  _tensor = Concatenate(axis = 3) ([_tensor, layers[j]]) # Merges feature maps\n",
        "\n",
        "  # ~Upsampling~\n",
        "\n",
        "  for i in range(0, 5):\n",
        "    ff2 = ff2 // 2\n",
        "    f = f // 2\n",
        "    _tensor = Conv2D(f, 3, activation = 'relu', padding = 'same') (_tensor)\n",
        "    _tensor = Conv2D(f, 3, activation = 'relu', padding = 'same') (_tensor)\n",
        "    _tensor = Conv2DTranspose(ff2, 2, strides = (2, 2), padding = 'same') (_tensor)\n",
        "    _tensor = Concatenate(axis = 3) ([_tensor, layers[j]])\n",
        "    j = j - 1\n",
        "  \n",
        "  _tensor = Conv2D(f, 3, activation = 'relu', padding = 'same') (_tensor)\n",
        "  _tensor = Conv2D(f, 3, activation = 'relu', padding = 'same') (_tensor)\n",
        "\n",
        "  outputs = Conv2D(1, 1, activation = 'sigmoid') (_tensor)\n",
        "\n",
        "  model = Model(inputs = [inputs], outputs = [outputs])\n",
        "  model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy')\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9xF231l0swW",
        "colab_type": "text"
      },
      "source": [
        "### Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMiiAVKi0w91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = make_model()\n",
        "model.fit(\n",
        "    x_train, # Training data\n",
        "    x_train, # Validation data (same as above)\n",
        "    verbose = 1,\n",
        "    epochs = num_epochs,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True,\n",
        "    validation_data = (x_test, x_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox9nORXA609Z",
        "colab_type": "text"
      },
      "source": [
        "### Show an example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKDVKO8563yS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_hat_test = model.predict(x_test[0])\n",
        "\n",
        "plt.figure(figsize = (1, 1))\n",
        "plt.imshow(x_test[0].reshape(img_size, img_size))\n",
        "plt.gray()\n",
        "plt.get_xaxis().set_visible(False)\n",
        "plt.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}